{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381fc340",
   "metadata": {},
   "source": [
    "<h1><center><font size = 10> Assignment 2 </font></center></h1>\n",
    "<h1><center><font size = 5> Author: Zach Chase </font></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bce192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031aafe",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "Data Exploration. Load the scikit-learn diabetes bunchobject into a variable. Print out the description of the dataset. Load the diabetesfeatures into a pandas dataframe with the proper column names. Add thetarget\n",
    "variable to this same dataframe. Run a command to look at the data typesof\n",
    "your dataframe to see if there is any missing data. Perform descriptive statisticson the numeric columns of your dataframe. Plot histograms of your datatoget afeel for each columnâ€™s distribution. Split your dataframe into a training andtest\n",
    "set with 20% of your data being in the test set. Define a correlation matrix. Lookat values highly correlated with the target. Plot the correlation matrix withaSeaborn heatmap. Use a Seaborn pairplot to look at the scatter plots of thethreevalues with the highest target correlation. Prepare a feature set by droppingthetarget from your training dataframe. Copy your training target into a newdataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teh data\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Print out the description\n",
    "diabetes.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fa37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "df['progression'] = diabetes.target # Add target variable\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ed8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad28a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8665dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,20))\n",
    "ax = fig.gca()\n",
    "df.hist(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28180489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['progression'], axis = 1).to_numpy()\n",
    "y = df['progression'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c074dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f5f24",
   "metadata": {},
   "source": [
    "The values with large correlations with the target variable are bmi, s5 and bp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eab5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['bmi', 's5', 'bp', 'progression']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.drop([\"progression\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ca0d",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Model Training. Train a linear regression model usingyour training set. Print the RMSE of your regression model on your trainingset.\n",
    "Implement a cross_val_score on a decision tree regressor on your trainingset. Print out root mean and standard deviation of the cross-validation scores. Dothesame for a RandomForestRegressor. Record which model performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "mean_squared_error(lr.predict(X_train), y_train, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f45691",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 0)\n",
    "scores = cross_val_score(dt, X_train, y_train, scoring='neg_mean_squared_error')\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "print('Scores:', tree_rmse_scores)\n",
    "print('Mean:', tree_rmse_scores.mean())\n",
    "print('Standard Deviation:', tree_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 0)\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring='neg_mean_squared_error')\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "print('Scores:', forest_rmse_scores)\n",
    "print('Mean:', forest_rmse_scores.mean())\n",
    "print('Standard Deviation:', forest_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd1231",
   "metadata": {},
   "source": [
    "Note that the linear regression model had a rmse of 53.5. Of the two other methods, the random forest regressor performed better with an rmse of 57.2, compared to the decision tree regressor which has an rmse of 75.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a7a1f",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "Model Tuning. Print out the parameters of your randomforest model. Do a grid search cross-validation with the following values:\n",
    "n_estimators: 3,10,30 and max_features: 2,4,6,8, as well as the followingexperiment: bootstrap: False, n_estimators: 3,10 and max_features: 2,3,4. Print\n",
    "out the best parameters and the best performing model based on this gridsearch. Using the cv_results dictionary, print out the rmse of each feature combinationforcomparison. Also print out the feature importances of the best performinggridsearch model. Describe how it compares with the correlation matrix we\n",
    "implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators': [3,10,30], 'max_features':[2,4,6,8]}, \n",
    "              {'bootstrap':[False], 'n_estimators':[3,10], 'max_features':[2,3,4]}]\n",
    "\n",
    "gridsearch = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9eab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(gridsearch.cv_results_['mean_test_score'], gridsearch.cv_results_['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = gridsearch.best_estimator_.feature_importances_\n",
    "sorted(zip(feature_importance, df.drop(['progression'], axis = 1)), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fcfc3",
   "metadata": {},
   "source": [
    "Note that the values we looked at earlier with the largest correlation values with our target variable were bmi, s5, and bp. These variables are 3 of the 4 most important according to our random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf520b44",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "Model Evaluation. Document the best-performingmodel\n",
    "between the single feature model you trained in Assignment 1, and the modelsyou trained in part 2 and 3 of this assignment. Evaluate the best performingmodel against your test set. Save your model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "diabetes_data = load_diabetes()\n",
    "X_bmi = diabetes_data.data\n",
    "y_bmi = diabetes_data.target\n",
    "\n",
    "X_train_bmi = X_bmi[:-20,2].reshape(-1,1)\n",
    "X_test_bmi = X_bmi[:20,2].reshape(-1,1)\n",
    "y_train_bmi = y_bmi[:-20].reshape(-1,1)\n",
    "y_test_bmi = y_bmi[:20].reshape(-1,1)\n",
    "\n",
    "diabetes_lm_bmi = LinearRegression().fit(X_train_bmi, y_train_bmi)\n",
    "\n",
    "value = mean_squared_error(y_train_bmi, diabetes_lm_bmi.predict(X_train_bmi), squared = False)\n",
    "print(\"Assignment 1 RMSE with train data using BMI only: \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = min(np.sqrt(-gridsearch.cv_results_['mean_test_score']))\n",
    "print(\"Random Forest RMSE with train data: \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1371c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = mean_squared_error(lr.predict(X_train), y_train, squared=False)\n",
    "print(\"Linear Regression RMSE with train data: \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_bmi = mean_squared_error(diabetes_lm_bmi.predict(X_test[:,2].reshape(-1,1)), y_test, squared = False)\n",
    "value_lr = mean_squared_error(lr.predict(X_test), y_test, squared=False)\n",
    "value_rf = mean_squared_error(gridsearch.best_estimator_.predict(X_test), y_test, squared = False)\n",
    "\n",
    "print(\"Linear Regression with BMI on test data RMSE: \", value_bmi)\n",
    "print(\"Linear Regression with all on test data RMSE: \", value_lr)\n",
    "print(\"Random Forest on test data RMSE: \", value_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084f31e",
   "metadata": {},
   "source": [
    "From these results it appears the model that performs best at minimizing RMSE is the Linear Regression model using all of the features. On the training data it has a RMSE of 53.52, and on the test data it has a RMSE of 54.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(lr, \"my_lr_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls my_lr_model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7b4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
